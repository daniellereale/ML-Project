{"cells":[{"cell_type":"markdown","metadata":{"id":"NSawdkqCTc7w"},"source":["\n","---\n","Supervised learning algorithm Decision Trees on Credit Card Transactions\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"km71MYX6O3bs"},"source":["### **Overview**\n","The following code splits the data 80/20. 80% is the training and 20% is validation. This decision tree algorithm takes the best threshold and best feature in order to make the tree. Precision, Accuracy, F1 Score, and Recall are calculated and printed out at the end. "]},{"cell_type":"markdown","metadata":{"id":"ugXIYM40XFU2"},"source":["### **Setting up classes and functions**\n","The following cell sets up the class Point in order to set up each transaction to have all of the features.  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJ1-dyxUZ6h_"},"outputs":[],"source":["#@title\n","class Point:\n","    def __str__(self):\n","        return \"<{}:{}>\".format(self.label, self.values)\n","    def __repr__(self):\n","        return \"<{}:{}>\".format(self.label, self.values)\n","    def __init__(self, label, values):\n","        self.label = label\n","        self.values = values\n"]},{"cell_type":"markdown","metadata":{"id":"aawgjTmtZ0ie"},"source":["\n","The following cell creates the class Tree in order to create the decision tree. The functions predict, accuracy, precision, F1 Score, and Recall are all created here.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7h-3i-1mdmAp"},"outputs":[],"source":["#@title\n","from math import log\n","import pickle as pkl\n","import matplotlib. pyplot as plt\n","class Tree:\n","    leaf = True\n","    prediction = None\n","    feature = None\n","    threshold = None\n","    left = None\n","    right = None\n","\n","def predict(tree, point):\n","    if tree.leaf:\n","        return tree.prediction\n","    i = tree.feature\n","    if (point.values[i] < tree.threshold):\n","        return predict(tree.left, point)\n","    else:\n","        return predict(tree.right, point)\n","\n","def most_likely_class(prediction):\n","    labels = list(prediction.keys())\n","    probs = list(prediction.values())\n","    return labels[probs.index(max(probs))]\n","\n","def accuracy(data, predictions):\n","    total = 0\n","    correct = 0\n","    for i in range(len(data)):\n","        point = data[i]\n","        pred = predictions[i]\n","        total += 1\n","        guess = most_likely_class(pred)\n","        if guess == point.label:\n","            correct += 1\n","    return float(correct) / total\n","\n","def precision(data, predictions):\n","    true_positives = 0\n","    pred_positives = 0\n","    for i in range(len(data)):\n","      point = data[i]\n","      pred = predictions[i]\n","      guess = most_likely_class(pred)\n","      if(point.label == 'is_fraud' and point.label == guess):\n","        true_positives += 1\n","    for j in range(len(data)):\n","      point = data[j]\n","      pred = predictions[j]\n","      guess = most_likely_class(pred) \n","      if(point.label == 'not_fraud' and guess == 'is_fraud'):\n","        pred_positives += 1\n","    return float(true_positives/(true_positives + pred_positives))\n","\n","def F1_Score(recall, precision):\n","  denominator = (1/recall) + (1/precision)\n","  return float(2 * (1/denominator))\n","\n","\n","def Recall(data, predictions):\n","  true_positives = 0\n","  pred_positives = 0\n","  for i in range(len(data)):\n","    point = data[i]\n","    pred = predictions[i]\n","    if(point.label == 'is_fraud' and point.label == most_likely_class(pred)):\n","      true_positives += 1\n","  for j in range(len(data)):\n","    point = data[j]\n","    pred = predictions[j]\n","    if(point.label == 'is_fraud' and most_likely_class(pred) == 'not_fraud'):\n","      pred_positives += 1\n","  return float(true_positives/(true_positives + pred_positives))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFslhrM0dr3J"},"outputs":[],"source":["def split_data(data, feature, threshold):\n","    left = []\n","    right = []\n","    #I am using a for loop to iterate through all the elements in the data\n","    for i in range(len(data)):\n","        #if the data value for that specific feature is less than the threshold then the full\n","        #data is added to the left. I am using append to add the data since left is a list\n","        if(data[i].values[feature] < threshold):\n","            left.append(data[i])\n","        else:\n","            #if the data value for that specific feature is greater than or equal to the threshold\n","            #then the full data is added to the right. I am using append to add the data to the right since it is a list\n","            right.append(data[i])\n","    #returning both left and right lists\n","    return (left, right)"]},{"cell_type":"markdown","metadata":{"id":"0ynd9drieIcx"},"source":["### **Creating functions to count the labels and calculate entropy**\n","\n","The count_labels function returns the number of times each label has occured. The function counts_to_entropy returns the entropy at each point using the following formula. \n"," $H(X) = -\\sum_{i} P(X=i) \\log_2 P(X=i)$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgWPwlRNewHX"},"outputs":[],"source":["def count_labels(data):\n","    counts = {}\n","    #using a for loop to iterate through the data\n","    #not using the length of the data because I have researched for loops in python \n","    #and a for loop works just the same without the length\n","    for point in data:\n","        #if the label of the specific element in data is in the dictionary counts\n","        #using the key function to help since it goes through count and gets the keys for me\n","        if(point.label in counts.keys()):\n","              #if the label is in count then the value of for that label is increased\n","              counts[point.label] += 1\n","        else:\n","              #if it is not then the label is created and set to 1\n","              counts[point.label] = 1\n","    #returning counts\n","    return counts\n","\n","def counts_to_entropy(counts):\n","    entropy = 0.0\n","    #creaing an index list to hold all of the values in count for each label\n","    index_list = list(counts.values())\n","    #if the length of the list is 0 then there are no elements and the entropy is 0.0\n","    if(len(index_list) == 0):\n","        entropy = 0.0\n","    else:\n","      #creating a variable to hold the total of the sum of the values in counts\n","      total = 0.0\n","      #using a for loop to go through each value in counts\n","      for index in counts.values():\n","          #adding the value to the total\n","          total += index\n","      #using a for loop to go through each value in counts again\n","      for value in counts.values():\n","          #calculating the probability using the formula found in the lecture slides\n","          probability = value / total\n","          #if the probability is 0 then that means that the value is 0\n","          if(probability == 0.0):\n","            #the entropy is then 0\n","            entropy = 0.0\n","          else:\n","            #if the probability is not 0 then the entropy is calculated using the\n","            #formula from the lecture slides. It is then added to the previous entropy since\n","            #entropy is the addition of the entropy of all the values\n","            entropy += (-1) * (probability * log(probability,2))\n","    #returning the entropy \n","    return entropy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LulRPKUqm6o7"},"outputs":[],"source":["#@title\n","def get_entropy(data):\n","    counts = count_labels(data)\n","    entropy = counts_to_entropy(counts)\n","    return entropy"]},{"cell_type":"markdown","metadata":{"id":"i5RuAuH_e5xC"},"source":["### **Determining the best threshold**\n","\n","The function find_best_threshold_fast takes the data and sorts it based on the feature. It then goes through the data to see which point of data produces the best gain and best threshold. \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdNiDtePff8-"},"outputs":[],"source":["def find_best_threshold_fast(data, feature):\n","    entropy = get_entropy(data)\n","    best_gain = 0\n","    best_threshold = None\n","                    \n","    #using the function sorted and specifying the feature and value to sort by\n","    #this makes running the code faster\n","\n","    data = sorted(data, key= lambda x:x.values[feature])\n","\n","    #At first I used a for loop to copy the data over but then it was running to slow \n","    #so I switched to using the copy method\n","    \n","    right = data.copy()\n","    #for i in range(len(data)):\n","    #    right.append(data[i])\n","    #creating a list left and setting it to empty\n","    left = []\n","    #creating a list counts right that will hold all of the labels in the data\n","    counts_right = count_labels(right)\n","    #creating a counts left to hold the labels that will be added\n","    counts_left = {}\n","    #using a for loop to go though each point in data\n","    for point in data:\n","        #I at first used get_entropy to find the data but then when I ran it it took too long\n","        #and was getting stuck in count labels so I had to change it\n","        #curr = (get_entropy(left)*len(left) + get_entropy(right)*len(right))/len(data)\n","        #getting the entropy of the data in left\n","        entropy_left = counts_to_entropy(counts_left)\n","        #getting the entropy in right\n","        entropy_right = counts_to_entropy(counts_right)\n","        #calculating the curr which is the total entropy \n","        curr = (entropy_left*len(left) + entropy_right*len(right))/len(data)\n","        #calculating the gain by subtracting curr from entropy\n","        gain = entropy - curr\n","        #if the gain is greater than the best gain  \n","        if gain > best_gain:\n","            #the best gain becomes the gain\n","            best_gain = gain\n","            #the best threshold becomes the value of that specific feature\n","            best_threshold = point.values[feature]\n","        #the next segmant of code was written using the pesudocode provided in the directions\n","        #the point is then added to the left\n","        left.append(point)\n","        #the point is then removd from the right\n","        right.remove(point)\n","        #creating a boolean to hold if the label is already in the counts left or counts right\n","        label_there = False\n","        #getting all the keys in counts left\n","        left_keys = counts_left.keys()\n","        #getting all the keys in counts right\n","        right_keys = counts_right.keys()\n","        #getting the label of the element in data that the for loop is on\n","        key = point.label\n","        #creating a boolean to see if the counts left or right is empty\n","        empty = False\n","        #if the length of counts left is 0 then it is empty and \n","        #empty is set to true\n","        if(len(counts_left) == 0):\n","            empty = True  \n","        elif(label_there == False):\n","            #if the label there is false then it means that the point label needs\n","            #to be checked to see if it is in left or right\n","            #using an if statement to see if the label is in counts left\n","            if key in left_keys:\n","                #if it is then the label there is set to true\n","                label_there = True\n","                #the value of the label in counts label is increased by 1\n","                counts_left[point.label] += 1\n","        #if the label is not in counts left or counts left is empty\n","        if(label_there == False or empty == True):\n","            #create a new label in counts left and set its value to 1\n","            counts_left[point.label] = 1 \n","        #if the label is in counts right then decrease the value of the label by 1\n","        if key in right_keys:\n","            counts_right[point.label] -= 1  \n","        \n","   \n","    #returning the best gain and best threshold\n","    return (best_gain, best_threshold)"]},{"cell_type":"markdown","metadata":{"id":"JfDphPVnfjZ2"},"source":["### **Determining the best split**\n","\n","The function find_best_split goes through each point in the data and determines which feature has the best gain and best threshold. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lIlBLkhftMr"},"outputs":[],"source":["def find_best_split(data):\n","    if len(data) < 2:\n","        return None, None\n","    best_feature = None\n","    best_threshold = None\n","    best_gain = 0\n","    #using a for loop to go through each feature. Using the first data point\n","    #since all the data points have the same number of features\n","    for index in range(len(data[0].values)):\n","      #calling best_threshold_fast to get the best threshold and best gain\n","       best_gain_i, best_threshold_i = find_best_threshold_fast(data, index)\n","       #if the gain is 0 then there is no best gain so best gain is none\n","       #best threshold is none and best feature is none\n","       if(best_gain_i == 0):\n","         best_gain = None\n","         best_threshold = None\n","         best_feature = None\n","       elif(best_gain_i > best_gain):\n","         #if the best gain of the feature is greater than the best_gain\n","         #that best feature, gain and threshold become the best gain feature and threshold \n","         best_gain = best_gain_i\n","         best_threshold = best_threshold_i\n","         best_feature = index\n","       elif(best_gain_i == best_gain):\n","         #if the best gain of the feature is  equal to the best_gain\n","         #that best feature, gain and threshold become the best gain feature and threshold \n","         best_gain = best_gain_i\n","         best_threshold = best_threshold_i\n","         best_feature = index\n","\n","    #returning the best feature and best threshold\n","    return (best_feature, best_threshold)"]},{"cell_type":"markdown","metadata":{"id":"hID2TQPQg2Nl"},"source":["### **Implementing c45 algorithm**###\n","\n","The following functions implement the c45 algorithm. Instead of only splitting the data 80/20 at the begining the c45 algorithm keeps splitting the data until there is no best gain. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f95jgAC4hKnb"},"outputs":[],"source":["def make_leaf(data):\n","    tree = Tree()   \n","    counts = count_labels(data)\n","    prediction = {}\n","    for label in counts:\n","        prediction[label] = float(counts[label])/len(data)\n","    tree.prediction = prediction\n","    return tree\n","\n","def c45(data, max_levels):\n","    if max_levels <= 0:\n","        return make_leaf(data)\n","\n","    #if the maximum level depth is reached has been taken care of with the if statement above\n","    #If all the points have the same label, then make a leaf with the data\n","    #first checking to see if the data has all the same labels\n","    #creating an empty list\n","    label_list = []\n","    #using a for loop to go through each element in the data\n","    for i in range(len(data)):\n","        #if the length of the list is 0 then nothing is in there and the label is added\n","        if(len(label_list) == 0):\n","            label_list.append(data[i].label)\n","        elif(len(label_list) == 1):\n","          #if the list only has one label checking to see if the data label is not the same\n","          #if it is not then adding it to the list\n","            if(data[i].label != label_list[0]):\n","                label_list.append(data[i].label)\n","        elif(len(label_list) == 2):\n","            #if the list has two labels checking to see if the data label is not the same\n","            #if it is not then adding it to the list\n","            if(data[i].label != label_list[0] and data[i].label != label_list[1]):\n","                label_list.append(data[i].label)\n","    \n","    #if the list only has one label then that means the data has the same labels\n","    #a leaf is then made\n","    if(len(label_list) == 1):\n","        return make_leaf(data) \n","    #in order to see if no split results in further gain the best feature and best threshold\n","    #need to be found\n","    best_feature, best_threshold = find_best_split(data)\n","    #if there is no best feature or best threshold then make a leaf\n","    if(best_feature == None and best_threshold == None):\n","        return make_leaf(data)\n","    else:\n","        #if the best feature and best threshold are found then split the data\n","        left, right = split_data(data, best_feature, best_threshold)\n","        #making a tree\n","        Make_tree = Tree()\n","        #setting the leaf to false  in order to Make an internal (non-leaf) node for that feature and threshold.\n","        Make_tree.leaf = False\n","        #setting the trees feature and threshold to the best feature and threshold\n","        Make_tree.feature = best_feature\n","        Make_tree.threshold = best_threshold\n","        #Creating the left and right subtrees of the node by recursing on the two partitions of the data.\n","        #setting the max_leves to max_levels -1 in order to eventually reach 0\n","        Make_tree.left = c45(left, max_levels - 1)\n","        Make_tree.right = c45(right, max_levels - 1)\n","    #returning the tree created\n","    return Make_tree"]},{"cell_type":"markdown","metadata":{"id":"hZBPzEGEhaF_"},"source":["### **Testing the data**\n","\n","The data contains about 2,000 transactions with half being fraudulent and the other half being infraudulent. The data is normalized.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KF006zYYdG8h"},"outputs":[],"source":["def testing(train, test, levels):\n","    tree = c45(train,levels)\n","    predictions = []\n","    \n","    for point in test:\n","        predictions.append(predict(tree, point))\n","    \n","    return predictions\n","\n","# This might be useful for debugging.\n","def print_tree(tree):\n","    if tree.leaf:\n","        print(\"Leaf\", tree.prediction)\n","    else:\n","        print(\"Branch\", tree.feature, tree.threshold)\n","        print_tree(tree.left)\n","        print_tree(tree.right)"]},{"cell_type":"markdown","metadata":{"id":"hq3hBWnHe4FT"},"source":["### **Gathering Dataset**\n","The dataset is loaded through google drive. The dataset was converted to all numbers prior to being loaded and then normalized. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ngLLq8LeyU0E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651241424750,"user_tz":240,"elapsed":1506,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}},"outputId":"c08056f2-f233-446d-8fcd-9b24fe34d04b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import sys\n","import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","new_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Normalized_data.csv')\n","from sklearn import preprocessing\n","scale = preprocessing.MinMaxScaler()\n","col = new_data.columns\n","result = scale.fit_transform(new_data)\n","df = pd.DataFrame(result, columns = col)\n","train, test = train_test_split(df, test_size=0.2)\n","array = []\n","for i in train['is_fraud'].keys():\n","  if(train['is_fraud'][i] == 1.0):\n","    label = 'is_fraud'\n","  else:\n","    label = 'not_fraud'\n","  array2 = []\n","  for j in train.keys():\n","    if(j == 'merch_long' or j == 'merch_lat' or j == 'job' or j == 'city_pop' or j == 'long' or j == 'lat' or j == 'zip' or j == 'state' or j == 'street' or j == 'last' or j == 'first' or j == 'amt'or j == 'category' or j == 'merchant' or j == 'city' or j == 'dob'):\n","      array2.append(train[j][i])\n","    \n","  array.append(Point(label, array2))\n","\n","train = array.copy()\n","fp_train = train\n","\n","array = []\n","for i in test['is_fraud'].keys():\n","  if(test['is_fraud'][i] == 1.0):\n","    label = 'is_fraud'\n","  else:\n","    label = 'not_fraud'\n","  array2 = []\n","  for j in test.keys():\n","    if(j == 'merch_long' or j == 'merch_lat' or j == 'job' or j == 'city_pop' or j == 'long' or j == 'lat' or j == 'zip' or j == 'state' or j == 'street' or j == 'last' or j == 'first' or j == 'amt' or j == 'category' or j == 'merchant'or j == 'city' or j == 'dob'):\n","      array2.append(test[j][i])\n","    \n","  \n","  array.append(Point(label, array2))\n","\n","test = array.copy()\n","fp_valid = test\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_4ORHSJtq3dV","colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"status":"ok","timestamp":1651241450102,"user_tz":240,"elapsed":25359,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}},"outputId":"8ef95a3c-7c23-4579-9715-07c73f1e13cc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["Accuracy is:0.9557109557109557\n","Precision is:0.9594594594594594\n","Recall is:0.9551569506726457\n","F1_Score is:0.957303370786517\n"]}],"source":["def test_data(fp_train, fp_valid):\n","    train = fp_train\n","    valid = fp_valid\n","    \n","    a_list = []\n","    x = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n","    for l in range(21):\n","      preds = testing(train, valid, l)\n","      acc = accuracy(valid, preds)\n","      a_list.append(acc)\n","    plt.plot(x, a_list)\n","    plt.title('Accuracy at maximum levels')\n","    plt.xlabel('max_levels')\n","    plt.ylabel('accuracy')\n","    plt.show()\n","    \n","    m = max(a_list)\n","    i = a_list.index(m)\n","    \n","    preds = testing(train, valid, x[i])\n","    acc = accuracy(valid, preds)\n","    print(\"Accuracy is:{}\".format(acc))\n","    prec = precision(valid, preds)\n","    print(\"Precision is:{}\".format(prec))\n","    recall = Recall(valid, preds)\n","    print(\"Recall is:{}\".format(recall))\n","    f1score = F1_Score(recall, prec)\n","    print(\"F1_Score is:{}\".format(f1score))\n","    \n","   \n","test_data(fp_train, fp_valid)\n"]},{"cell_type":"markdown","metadata":{"id":"D3tdlutPf_pc"},"source":["### **Acknowledgments**###\n","This algorithm of decision trees was adapted using the ECE 4424 course Homework 1. \n","\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Project_Decision_Trees.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}