{"cells":[{"cell_type":"markdown","metadata":{"id":"yhq4HZ-G04dj"},"source":["\n","---\n","Supervised Learning Algorithm Logistic Regression on Credit Card Transactions\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0Nk3V3fs1N0B"},"source":["### **Overview**\n","The following code trains logistic regression via stochastic gradient-based optimization for predicting fraudelent transactions from data having various features such as job, city population, xipcode, state, city, amount, first name, last name and others. With the training data the code will predict whether a transaction was fraudulent or not. Feature engineering is used in order to get the greatest accuracy. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"FqbuYSDzqv1r"},"source":["### **Implementing the Logistic Function [5 points]**####\n","\n","The following logistic regression model was chosen and implemented. \n","$$a = \\frac{1}{1+e^{-b}}$$\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_5tuRhuyr7WE","executionInfo":{"status":"ok","timestamp":1651265802542,"user_tz":240,"elapsed":155,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":["from math import exp\n","import random\n","random.seed(1)\n","def logistic(x):\n","    #using the formula above s is a in the formula\n","    #calculating the denominator\n","    denominator = 1 + (exp(-x))\n","    #calculating s to be 1 over the denominator value calculated\n","    s = 1/denominator\n","    #returning s\n","    return s"]},{"cell_type":"markdown","metadata":{"id":"OJpYnuANsDZy"},"source":["### **Implementing the Dot Product [10 points]**###\n","\n","The function dot calculates the dot product of two vectors. The following formula is used to calculate the product. \n","\n","\n","$\\mathbf a\\mathbf \\cdot \\mathbf b = \\sum_{i=1}^n a_i b_i = a_1b_1 + a_2 b_2 + ... + a_n b_n$\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"St-LgcKEsFyY","executionInfo":{"status":"ok","timestamp":1651265802543,"user_tz":240,"elapsed":5,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":["def dot(x, y):\n","    #the dot product is the element in one index times the element in the other \n","    #list with the same index\n","    #starting with s being 0 to initialize it\n","    s = 0\n","    #using a for loop to go through the length of the list\n","    for i in range(len(x)):\n","      #adding to s the product of the elements in the list\n","      s = s + (x[i] * y[i])\n","    #returning s\n","    return s"]},{"cell_type":"markdown","metadata":{"id":"3Rr1jtjmsXy9"},"source":["### **Implementing the Prediction function for each data point**###\n","\n","The function predict takes the dot product of the model's weights and the features and then takes the logistic regression. \n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"vf5HqXzWstBA","executionInfo":{"status":"ok","timestamp":1651265802543,"user_tz":240,"elapsed":5,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":["def predict(model, point):\n","    #calculating the dot product the same as above but with the weights\n","    #starting off p as 0 to initialize it\n","    p = 0\n","    #using a for loop to go through the length of the model list\n","    for i in range(len(model)):\n","      #adding to p the product of each weight times the feature\n","      p = p + (model[i] * point['features'][i])\n","    #calling the logistic function on p \n","    p = logistic(p)\n","    #returning p\n","    return p"]},{"cell_type":"markdown","metadata":{"id":"9VWBaiVhiNzw"},"source":["### **Gathering data**###\n","\n","The dataset is loaded from google drive. The dataset is then reduced to only \n","2,000 points since the original data was very unbalanced. \n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"noyeUdF99ckG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651265819739,"user_tz":240,"elapsed":17200,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}},"outputId":"40254286-976c-4262-d0c0-64fe23da760d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"NH_u_CJj9dHT","executionInfo":{"status":"ok","timestamp":1651265819740,"user_tz":240,"elapsed":7,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":["import csv\n","\n","def load_csv(filename):\n","    lines = []\n","    counter_1 = 0\n","    counter_0 = 0\n","    with open(filename) as csvfile:\n","        reader = csv.DictReader(csvfile)\n","        for line in reader:\n","          if(line['is_fraud'] == '0'):\n","            if(counter_0 < 1072):\n","              lines.append(line)\n","              counter_0 += 1\n","          else:\n","            if(counter_1 < 1072):\n","              lines.append(line)\n","              counter_1 += 1\n","    return lines\n","\n","def load_adult_data(fn):\n","    return load_csv(fn)\n","\n","def load_adult_train_data(fn):\n","    return load_adult_data(fn)\n","\n","def load_adult_valid_data(fn):\n","    return load_adult_data(fn)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"qV336G0TKg0Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651265827705,"user_tz":240,"elapsed":7970,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}},"outputId":"06aa165f-bc30-4c38-cdf6-a86e5347806b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Path to adult.data: /content/drive/My Drive/Colab Notebooks/fraudTest.csv\n"]}],"source":["#Append the directory to your python path using sys\n","import sys\n","import os\n","import matplotlib.pyplot as plt\n","prefix = '/content/drive/My Drive/'\n","# modify \"customized_path_to_your_homework\" here to where you uploaded your homework\n","customized_path_to_your_homework = 'Colab Notebooks/'\n","sys_path = prefix + customized_path_to_your_homework\n","sys.path.append(sys_path)\n","\n","\n","\n","fp_data = os.path.join(sys_path, 'fraudTest.csv')\n","data = load_adult_train_data(fp_data)\n","print('Path to adult.data: {}'.format(fp_data))"]},{"cell_type":"markdown","metadata":{"id":"y1QfcRnZx4wF"},"source":["### **Calculating Accuracy, Precision, F1 Score, Recall**###\n","\n","The accuracy is calculated using 0.5 as a threshold. Above 0.5 is True, below is False. \n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"IL2Zdrj_x77-","executionInfo":{"status":"ok","timestamp":1651265827706,"user_tz":240,"elapsed":22,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":["def accuracy(data, predictions):\n","    #setting a counter for the number of times the predicted-real value is correct\n","    correct = 0;\n","    #using a for loop to go through the data\n","    for i in range(len(data)):\n","      #setting holder to 0 which sets the number of the prediction to 0 by default\n","      holder = 0\n","      #f the prediction valu ei sgreater than or equal to 0.5 then it is true\n","      #and holder is set to 1\n","      if(predictions[i] >= 0.5):\n","        holder = 1\n","      #if the holder value is equal to the label value then the prediction \n","      #was correct and correct is incremented\n","      if(holder == data[i]['label']):\n","        correct += 1\n","\n","    #returning the number of correctly predicted data points over the \n","    #total points\n","    return float(correct)/len(data)\n","def precision(data, predictions):\n","    true_pos = 0\n","    false_pos = 0\n","    for i in range(len(data)):\n","      holder = 0\n","      if(predictions[i] >= 0.5):\n","        holder = 1\n","      if(holder == 1 and holder == data[i]['label'] ):\n","        true_pos += 1\n","      if(holder == 1 and holder != data[i]['label']):\n","        false_pos += 1\n","    return true_pos / (true_pos + false_pos)\n","\n","def recall(data, predictions):\n","    true_pos = 0\n","    false_neg = 0\n","    for i in range(len(data)):\n","      holder = 0\n","      if(predictions[i] >= 0.5):\n","        holder = 1\n","      if(holder == 1 and holder == data[i]['label']):\n","        true_pos += 1\n","      if(holder == 0 and holder != data[i]['label']):\n","        false_neg += 1\n","    return true_pos / (true_pos + false_neg)\n","\n","def F1Score(precision, recall):\n","  denominator = (1/precision) + (1/recall)\n","  return 2 * (1/denominator)\n","\n","    \n","\n"]},{"cell_type":"markdown","metadata":{"id":"sY4p5ROoyIwV"},"source":["### **Training**###\n","\n","The update rule as seen below is used for stochastic gradient descent. \n","\n","\n","$$w_i^{(t+1)} \\leftarrow w_i^{(t)} - \\eta \\lambda w_i^{(t)} + \\eta \\sum_l X_i^l (Y^l -\\hat P(Y^l=1| X^l, W))$$\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"8_MmxkPtyRqk","executionInfo":{"status":"ok","timestamp":1651265827707,"user_tz":240,"elapsed":21,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":["def initialize_model(k):\n","    return [random.gauss(0, 1) for x in range(k)]\n","\n","def train(data, epochs, rate, lam):\n","    model = initialize_model(len(data[0]['features']))\n","    #I went to office hours with Hongjie Chen and Chongyu He. They were both  \n","    #very helpful and explained to me the formula. Hongjie Chen helped me set\n","    #up the for loops.\n","    \n","    #using a for loop to go through the number of iterations of epochs\n","    for t_epoch in range(epochs):\n","      #setting w as a list to hold each updated weight value \n","      w = []\n","      #using a for loop to go through the length of model\n","      for i_model in range(len(model)):\n","        #calculating the second term in the formula\n","        second_term = rate * lam * model[i_model]\n","        #setting the third_term to 0 to initialize it because the formula\n","        #requires the sum over length l\n","        third_term = 0\n","        #using a for loop  to go over each element in the data\n","        for l_data in range(len(data)):\n","          #getting the random number for the index from 0 to n n will be exclusive\n","          index = random.randrange(0, (len(data)))\n","          #the x paramter when calling dot function will be the model from 1 to the last\n","          #because the formula for the probability that I used from the \n","          #lecture slides starts at index 1\n","          dot_x = model[1:]\n","          #the y paramter when calling dot function will be the model from 1 to the last\n","          #because the formula for the probability that I used from the \n","          #lecture slides starts at index 1\n","          dot_y = data[index]['features'][1:]\n","          #calculating the numerator of the probability \n","          #function found in the slides\n","          #using dot instead of predict because I was getting an error and using \n","          #parametric form\n","          exponential = exp(model[0] + dot(dot_x, dot_y))\n","          #calculating the third term of the formula above\n","          third_term = third_term + data[index]['features'][i_model] * (int(data[index]['label']) - (exponential / (1 + exponential)))\n","        #calculating the next weight by subtracting and adding the elements\n","        next_weight = model[i_model] - second_term + (rate * third_term)\n","        #adding the next_weight to the list\n","        w.append(next_weight)\n","      #setting the model to the new list of weights that were calculated\n","      model = w.copy()\n","      \n","      \n","\n","\n","    #returning model\n","    return model\n","    "]},{"cell_type":"markdown","metadata":{"id":"cUKzKdKrydLn"},"source":["### **Feature Engineering**###\n","\n","In order to produce the best results feature engineering is used. A number of features were tested in order to improve the model. \n"," "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"LIqwzBKRyh7X","executionInfo":{"status":"ok","timestamp":1651265827707,"user_tz":240,"elapsed":20,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":["def extract_features(raw):\n","    data = []\n","    for r in raw:\n","        point = {}\n","        point[\"label\"] = (r['is_fraud'] == '1')\n","       \n","\n","        features = []\n","        \n","\n","        #in order to see which features to add I opened the data in excel and \n","        #looked at each category and which answers appeared the most.\n","        #I then added them here and ran the code to see if the accurracy increased\n","        #or decreased. \n","        features.append(r['state'] == 'FL')\n","        features.append(float(r['amt']) >= 200)\n","        features.append(float(r['city_pop']) <= 1000)\n","        features.append(float(r['lat'])/61)\n","        features.append(r['category'] == 'travel')\n","        features.append(r['category'] == 'shopping_pos')\n","        \n","        \n","        \n","        \n","        point['features'] = features\n","        data.append(point)\n","    return data"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"eVkKBs7XE0Pf","executionInfo":{"status":"ok","timestamp":1651265827708,"user_tz":240,"elapsed":20,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"Ylr1ze1gy1HZ"},"source":["### **Tuning**###\n","\n","Different learning rates and parameters are tried in order to optimize the results. \n","\n","\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"--bZEA4GrB8_","executionInfo":{"status":"ok","timestamp":1651265827856,"user_tz":240,"elapsed":167,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}}},"outputs":[],"source":["def tuning(data, epochs):\n","    random.seed(1)\n","    #In order to increase accuracy I started by decreasing the rate\n","    #I then increased the epochs and ran the program numerous times to see what \n","    #gave the best results\n","    return train(data, epochs, .6e-3, 1e-2) \n","    \n","    "]},{"cell_type":"code","execution_count":12,"metadata":{"id":"8CM8gcd13TQS","colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"status":"error","timestamp":1651265855156,"user_tz":240,"elapsed":27302,"user":{"displayName":"Danielle Reale","userId":"16131780282077933008"}},"outputId":"b470d60d-95ec-43dc-bb8e-1fed5b6f7523"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-125082e2bcc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF1Score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPrecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-125082e2bcc1>\u001b[0m in \u001b[0;36mtest_data\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ma_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-d98641679fc3>\u001b[0m in \u001b[0;36mtuning\u001b[0;34m(data, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#I then increased the epochs and ran the program numerous times to see what\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#gave the best results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.6e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-ba0241b552f4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, epochs, rate, lam)\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0mexponential\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0;31m#calculating the third term of the formula above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m           \u001b[0mthird_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthird_term\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_model\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexponential\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexponential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;31m#calculating the next weight by subtracting and adding the elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mnext_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_model\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msecond_term\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthird_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def test_data(fn):\n","    test_data = extract_features(load_adult_train_data(fn))\n","    x_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n","    a_list = []\n","    for i in x_list:\n","      model = tuning(test_data, i)\n","      predictions = [predict(model, p) for p in test_data]  \n","      acc = accuracy(test_data, predictions)\n","      a_list.append(acc)\n","    plt.plot(x_list, a_list)\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.title('Accuracy over each epoch')\n","    plt.show()\n","\n","    m = max(a_list)\n","    ind = a_list.index(m)\n","    model = tuning(test_data, x_list[ind])\n","    predictions = [predict(model, p) for p in test_data]    \n","    print(\"Accuracy:\", accuracy(test_data, predictions))\n","    Precision = precision(test_data, predictions)\n","    print(\"Precision:\", Precision)\n","    Recall = recall(test_data, predictions)\n","    print(\"Recall:\", Recall)\n","    print(\"F1Score:\", F1Score(Precision, Recall))\n","test_data(fp_data)"]},{"cell_type":"markdown","metadata":{"id":"QTvn6PIaPy6r"},"source":["### **Acknowledgments**###\n","\n","This algorithm of logistic regression was adapted using the ECE 4424 course Homework 2. "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Project_Logistic_Regression.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}